{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning Hubble Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from matplotlib.pyplot import *\n",
    "\n",
    "from transfer_learning.fingerprint import FingerprintResnet\n",
    "from transfer_learning.data_processing import CropData, GrayScaleData\n",
    "from transfer_learning.cutouts import FullImageCutout\n",
    "from transfer_learning.similarity import tSNE, Jaccard, Distance\n",
    "from transfer_learning.transfer_learning import TransferLearning\n",
    "from transfer_learning.transfer_learning_display import TransferLearningDisplay\n",
    "import pickle\n",
    "\n",
    "# Full width \n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Meta Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to create/load the information corresponding to the images.  The pickle file contains a list of dictionaries. Each dictionary corresponds to a hubble image and has the location (in this case hosted off an AWS site), RA/DEC and meta information. The meta information comes directly from astroquery.mast data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_dict = pickle.load(open('../data/hubble_acs.pck', 'rb'))\n",
    "print(processing_dict[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fingerprint Creator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create a fingerprint creator / classifier.  This method takes an image and calculates the corresponding weighted predictions based on the ImageNet data and a pre-trained network.  In this case we are going to use the ResNet50 pre-trained network but we could also use the VGG16, VGG19 etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fingerprint_model = FingerprintResnet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image pre-processing model will be passed in to the transfer learning code and will be applied to each image before the classification/fingerprint is calculated.  In this case, we are going to use the full image (cropped to 224 x 224 as required by ImageNet) and then make sure it is formatted as gray scale (which all the images should be in this case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_cutout = FullImageCutout(output_size=224)\n",
    "\n",
    "# Added Gray Scale as some were 3 channel gray scale\n",
    "data_processing = [\n",
    "            [CropData(), GrayScaleData()],\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ## Calculate the Fingerprints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we finally get to the part where the fingerprints are calculated. The transfer learning module takes the cutout, data processing and fingerprint modules defined above and then calculate_stream is called on the first 100 images (for example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl = TransferLearning(basic_cutout, data_processing, fingerprint_model)\n",
    "tl.calculate_stream(processing_dict[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity Calculator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we display the similarity between the images we need to define how we are going to calculate the similarities. In this case we are going to use the tSNE data reduction method.  Though we could also use a set similarity method (Jaccard) or distance metric (Distance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = tSNE(display_type='hexbin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to calculate create the display code based on the type of simiilarity that was set above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tld = TransferLearningDisplay(similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning Simiarlity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you show the transfer learning display (next command) you will see a tSNE plot in the lower left, 9 images on the right and an Aitoff plot on the top left.  Click somewhere in the tSNE plot and it will display the corresponding image in the top left of the 9 images and show you the 8 corresponding similar images. You can hover over one of the 9 images to see the meta information about it along with the top 8 corresponding ImageNet image classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tld.show(tl.fingerprints)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
